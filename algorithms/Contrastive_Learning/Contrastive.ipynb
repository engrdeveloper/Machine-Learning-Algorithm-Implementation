{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IkHN3UCzOAr",
        "outputId": "da6ca154-a347-4037-abaf-49dffa72f9b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity of positive pair (x1,x2): 1.00\n",
            "Similarity of negative pair (x1,x3): 0.71\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Two 1D points\n",
        "x1 = torch.tensor([1.0, 2.0])\n",
        "x2 = torch.tensor([1.1, 2.1])\n",
        "x3 = torch.tensor([15.0, 5.0])\n",
        "\n",
        "# cosine similarity\n",
        "def similarity(a, b):\n",
        "    return F.cosine_similarity(a, b, dim=0)\n",
        "\n",
        "# Compute similarities\n",
        "sim_positive = similarity(x1, x2)  # should be high\n",
        "sim_negative = similarity(x1, x3)  # should be low\n",
        "\n",
        "print(f\"Similarity of positive pair (x1,x2): {sim_positive.item():.2f}\")\n",
        "print(f\"Similarity of negative pair (x1,x3): {sim_negative.item():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXJGDsPS3VKh",
        "outputId": "488298db-25ec-45d8-88f0-8b448acda0f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0: loss=-0.011, sim_pos=-0.989, sim_neg=-1.000\n",
            "Step 10: loss=-0.074, sim_pos=-0.913, sim_neg=-0.988\n",
            "Step 20: loss=-0.378, sim_pos=-0.544, sim_neg=-0.923\n",
            "Step 30: loss=-1.040, sim_pos=0.239, sim_neg=-0.800\n",
            "Step 40: loss=-1.526, sim_pos=0.720, sim_neg=-0.806\n",
            "Step 50: loss=-1.771, sim_pos=0.882, sim_neg=-0.889\n",
            "Step 60: loss=-1.892, sim_pos=0.946, sim_neg=-0.946\n",
            "Step 70: loss=-1.950, sim_pos=0.975, sim_neg=-0.975\n",
            "Step 80: loss=-1.977, sim_pos=0.989, sim_neg=-0.988\n",
            "Step 90: loss=-1.989, sim_pos=0.995, sim_neg=-0.995\n",
            "\n",
            "Final embeddings:\n",
            "z1: tensor([-0.1406,  1.0163], requires_grad=True)\n",
            "z2: tensor([-0.3305,  1.5748], requires_grad=True)\n",
            "z3: tensor([ 0.1098, -1.6142], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Initialize \"embeddings\" from scratch\n",
        "# Let's say we have 3 points in 2D space (random init)\n",
        "z1 = torch.randn(2, requires_grad=True)\n",
        "z2 = torch.randn(2, requires_grad=True)\n",
        "z3 = torch.randn(2, requires_grad=True)  # negative\n",
        "\n",
        "# Cosine similarity function\n",
        "def similarity(a, b):\n",
        "    return F.cosine_similarity(a, b, dim=0)\n",
        "\n",
        "# Learning rate\n",
        "lr = 0.1\n",
        "\n",
        "optimizer = optim.SGD([z1, z2, z3], lr=0.1)\n",
        "\n",
        "# Training loop\n",
        "for step in range(100):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Cosine similarities\n",
        "    sim_pos = similarity(z1, z2)\n",
        "    sim_neg = similarity(z1, z3)\n",
        "\n",
        "    # Contrastive loss: maximize positive, minimize negative\n",
        "    loss = -(sim_pos - sim_neg)\n",
        "\n",
        "    # Compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}: loss={loss.item():.3f}, sim_pos={sim_pos.item():.3f}, sim_neg={sim_neg.item():.3f}\")\n",
        "\n",
        "# Final embeddings\n",
        "print(\"\\nFinal embeddings:\")\n",
        "print(\"z1:\", z1)\n",
        "print(\"z2:\", z2)\n",
        "print(\"z3:\", z3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i51sZIh8rHM",
        "outputId": "99b25efe-9f0d-48f1-d9ad-8c4c0682eed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<generator object Module.parameters at 0x7cec58394d60>\n",
            "Step 0: loss=-0.131, sim_pos=0.999, sim_neg=0.868\n",
            "Step 10: loss=-2.000, sim_pos=1.000, sim_neg=-1.000\n",
            "Step 20: loss=-2.000, sim_pos=1.000, sim_neg=-1.000\n",
            "Step 30: loss=-2.000, sim_pos=1.000, sim_neg=-1.000\n",
            "Step 40: loss=-2.000, sim_pos=1.000, sim_neg=-1.000\n",
            "Step 50: loss=-2.000, sim_pos=1.000, sim_neg=-1.000\n",
            "Step 60: loss=-2.000, sim_pos=1.000, sim_neg=-1.000\n",
            "Step 70: loss=-2.000, sim_pos=1.000, sim_neg=-1.000\n",
            "Step 80: loss=-2.000, sim_pos=1.000, sim_neg=-1.000\n",
            "Step 90: loss=-2.000, sim_pos=1.000, sim_neg=-1.000\n",
            "\n",
            "Final embeddings:\n",
            "z1: tensor([-0.2879,  0.6153], grad_fn=<ViewBackward0>)\n",
            "z2: tensor([-0.2802,  0.6018], grad_fn=<ViewBackward0>)\n",
            "z3: tensor([ 1.7130, -3.6618], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "x1 = torch.tensor([1.0, 2.0])\n",
        "x2 = torch.tensor([1.1, 2.1])  # positive\n",
        "x3 = torch.tensor([15.0, 5.0]) # negative\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(2, 4)  # hidden layer 2 → 4\n",
        "        self.fc2 = nn.Linear(4, 2)  # output layer 4 → 2\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Cosine similarity function\n",
        "def similarity(a, b):\n",
        "    return F.cosine_similarity(a, b, dim=0)\n",
        "\n",
        "# Learning rate\n",
        "lr = 0.1\n",
        "\n",
        "encoder = Encoder()\n",
        "print(encoder.parameters())\n",
        "optimizer = optim.SGD(encoder.parameters(), lr=0.1)\n",
        "\n",
        "# Training loop\n",
        "for step in range(100):\n",
        "    z1 = encoder(x1)\n",
        "    z2 = encoder(x2)\n",
        "    z3 = encoder(x3)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Cosine similarities\n",
        "    sim_pos = similarity(z1, z2)\n",
        "    sim_neg = similarity(z1, z3)\n",
        "\n",
        "    # Contrastive loss: maximize positive, minimize negative\n",
        "    loss = -(sim_pos - sim_neg)\n",
        "\n",
        "    # Compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}: loss={loss.item():.3f}, sim_pos={sim_pos.item():.3f}, sim_neg={sim_neg.item():.3f}\")\n",
        "\n",
        "# Final embeddings\n",
        "z1 = encoder(x1)\n",
        "z2 = encoder(x2)\n",
        "z3 = encoder(x3)\n",
        "print(\"\\nFinal embeddings:\")\n",
        "print(\"z1:\", z1)\n",
        "print(\"z2:\", z2)\n",
        "print(\"z3:\", z3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUO8L73F_wjg",
        "outputId": "ec48833f-100a-4ccb-fb1c-4c9a3856438e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0: loss=-0.125, sim_pos=0.662, sim_neg=0.536\n",
            "Step 1: loss=-0.119, sim_pos=0.477, sim_neg=0.358\n",
            "Step 2: loss=0.156, sim_pos=0.660, sim_neg=0.816\n",
            "Step 3: loss=0.038, sim_pos=0.894, sim_neg=0.932\n",
            "Step 4: loss=0.217, sim_pos=0.729, sim_neg=0.947\n",
            "Step 5: loss=0.002, sim_pos=0.941, sim_neg=0.943\n",
            "Step 6: loss=0.015, sim_pos=0.934, sim_neg=0.949\n",
            "Step 7: loss=-0.016, sim_pos=0.930, sim_neg=0.914\n",
            "Step 8: loss=0.009, sim_pos=0.873, sim_neg=0.882\n",
            "Step 9: loss=0.047, sim_pos=0.883, sim_neg=0.930\n",
            "Step 10: loss=0.027, sim_pos=0.896, sim_neg=0.923\n",
            "Step 11: loss=-0.040, sim_pos=0.976, sim_neg=0.936\n",
            "Step 12: loss=-0.022, sim_pos=0.954, sim_neg=0.932\n",
            "Step 13: loss=0.033, sim_pos=0.943, sim_neg=0.975\n",
            "Step 14: loss=-0.024, sim_pos=0.962, sim_neg=0.937\n",
            "Step 15: loss=0.021, sim_pos=0.878, sim_neg=0.900\n",
            "Step 16: loss=0.012, sim_pos=0.954, sim_neg=0.966\n",
            "Step 17: loss=0.006, sim_pos=0.951, sim_neg=0.957\n",
            "Step 18: loss=-0.032, sim_pos=0.965, sim_neg=0.933\n",
            "Step 19: loss=0.031, sim_pos=0.933, sim_neg=0.964\n",
            "Step 20: loss=0.005, sim_pos=0.963, sim_neg=0.968\n",
            "Step 21: loss=0.011, sim_pos=0.923, sim_neg=0.933\n",
            "Step 22: loss=0.014, sim_pos=0.938, sim_neg=0.952\n",
            "Step 23: loss=-0.019, sim_pos=0.931, sim_neg=0.911\n",
            "Step 24: loss=0.018, sim_pos=0.952, sim_neg=0.970\n",
            "Step 25: loss=0.005, sim_pos=0.937, sim_neg=0.942\n",
            "Step 26: loss=-0.007, sim_pos=0.966, sim_neg=0.959\n",
            "Step 27: loss=0.011, sim_pos=0.944, sim_neg=0.955\n",
            "Step 28: loss=0.060, sim_pos=0.895, sim_neg=0.955\n",
            "Step 29: loss=0.045, sim_pos=0.928, sim_neg=0.973\n",
            "Step 30: loss=-0.029, sim_pos=0.958, sim_neg=0.929\n",
            "Step 31: loss=-0.024, sim_pos=0.933, sim_neg=0.909\n",
            "Step 32: loss=0.072, sim_pos=0.868, sim_neg=0.940\n",
            "Step 33: loss=-0.001, sim_pos=0.966, sim_neg=0.965\n",
            "Step 34: loss=-0.022, sim_pos=0.968, sim_neg=0.946\n",
            "Step 35: loss=-0.013, sim_pos=0.939, sim_neg=0.925\n",
            "Step 36: loss=0.003, sim_pos=0.965, sim_neg=0.968\n",
            "Step 37: loss=0.008, sim_pos=0.952, sim_neg=0.961\n",
            "Step 38: loss=0.047, sim_pos=0.923, sim_neg=0.971\n",
            "Step 39: loss=-0.003, sim_pos=0.961, sim_neg=0.958\n",
            "Step 40: loss=-0.018, sim_pos=0.958, sim_neg=0.940\n",
            "Step 41: loss=-0.009, sim_pos=0.945, sim_neg=0.936\n",
            "Step 42: loss=0.019, sim_pos=0.960, sim_neg=0.979\n",
            "Step 43: loss=-0.052, sim_pos=0.934, sim_neg=0.882\n",
            "Step 44: loss=-0.041, sim_pos=0.935, sim_neg=0.894\n",
            "Step 45: loss=-0.010, sim_pos=0.960, sim_neg=0.950\n",
            "Step 46: loss=0.072, sim_pos=0.877, sim_neg=0.949\n",
            "Step 47: loss=0.026, sim_pos=0.937, sim_neg=0.963\n",
            "Step 48: loss=-0.132, sim_pos=0.960, sim_neg=0.828\n",
            "Step 49: loss=0.010, sim_pos=0.928, sim_neg=0.938\n",
            "Step 50: loss=0.010, sim_pos=0.933, sim_neg=0.944\n",
            "\n",
            "Learned parameters:\n",
            "conv1.weight torch.Size([16, 1, 3, 3])\n",
            "conv1.bias torch.Size([16])\n",
            "conv2.weight torch.Size([32, 16, 3, 3])\n",
            "conv2.bias torch.Size([32])\n",
            "fc1.weight torch.Size([128, 6272])\n",
            "fc1.bias torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Dataset + simple transform ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True)  # small batch\n",
        "\n",
        "# CNN Encoder ---\n",
        "class CNNEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)  # 28x28 -> 28x28\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # 28x28 -> 14x14\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1)  # 14x14 -> 14x14\n",
        "        self.fc1 = nn.Linear(32*14*14, 128)  # flatten -> 128-dim embedding\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)  # flatten\n",
        "        x = self.fc1(x)\n",
        "        x = F.normalize(x, dim=1)  # normalize embedding\n",
        "        return x\n",
        "\n",
        "encoder = CNNEncoder()\n",
        "optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n",
        "\n",
        "#  Training loop ---\n",
        "for step, (images, labels) in enumerate(loader):\n",
        "    if step > 50:  # few batches for demo\n",
        "        break\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Take first 3 images as anchor, positive, negative\n",
        "    img_anchor = images[0].unsqueeze(0)   # add batch dim\n",
        "    img_positive = images[1].unsqueeze(0)\n",
        "    img_negative = images[2].unsqueeze(0)\n",
        "\n",
        "    z_anchor = encoder(img_anchor)\n",
        "    z_pos = encoder(img_positive)\n",
        "    z_neg = encoder(img_negative)\n",
        "\n",
        "    sim_pos = F.cosine_similarity(z_anchor, z_pos)\n",
        "    sim_neg = F.cosine_similarity(z_anchor, z_neg)\n",
        "\n",
        "    loss = -(sim_pos - sim_neg)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Step {step}: loss={loss.item():.3f}, sim_pos={sim_pos.item():.3f}, sim_neg={sim_neg.item():.3f}\")\n",
        "\n",
        "# Print learned parameters ---\n",
        "print(\"\\nLearned parameters:\")\n",
        "for name, param in encoder.named_parameters():\n",
        "    print(name, param.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Oo3aOc1m9MM-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
